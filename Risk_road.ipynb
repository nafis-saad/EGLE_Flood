{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a553c360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"D:/Flood_Project/Model_running/Trail Run-3/Network_file_preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9abcac59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41c41bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = pd.read_csv('SEMCOG_Risk_Road.csv',   low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c69e769d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RoadSegmen</th>\n",
       "      <th>PR</th>\n",
       "      <th>Linearef</th>\n",
       "      <th>FETYPE</th>\n",
       "      <th>FENAME</th>\n",
       "      <th>BMP</th>\n",
       "      <th>EMP</th>\n",
       "      <th>all_roads_</th>\n",
       "      <th>spatialjoi</th>\n",
       "      <th>spatialj_1</th>\n",
       "      <th>...</th>\n",
       "      <th>all_roads1</th>\n",
       "      <th>perrank_nf</th>\n",
       "      <th>perrank_cr</th>\n",
       "      <th>perrank_vu</th>\n",
       "      <th>perrank_ri</th>\n",
       "      <th>tampnum_ne</th>\n",
       "      <th>ramp</th>\n",
       "      <th>completed_</th>\n",
       "      <th>risk_level</th>\n",
       "      <th>shape_Leng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278779</td>\n",
       "      <td>964704</td>\n",
       "      <td>9647047400002074000008</td>\n",
       "      <td>Rd</td>\n",
       "      <td>Lakeshore Rd</td>\n",
       "      <td>12.517</td>\n",
       "      <td>12.598</td>\n",
       "      <td>147</td>\n",
       "      <td>Lakeshore Rd</td>\n",
       "      <td>Huron Walk</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.465</td>\n",
       "      <td>1.765417</td>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>426.267071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>279137</td>\n",
       "      <td>964704</td>\n",
       "      <td>9647047400002874000020</td>\n",
       "      <td>Rd</td>\n",
       "      <td>Lakeshore Rd</td>\n",
       "      <td>12.412</td>\n",
       "      <td>12.517</td>\n",
       "      <td>147</td>\n",
       "      <td>Lakeshore Rd</td>\n",
       "      <td>Huron Walk</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.465</td>\n",
       "      <td>1.765417</td>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low</td>\n",
       "      <td>555.969541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RoadSegmen      PR                Linearef FETYPE        FENAME     BMP  \\\n",
       "0      278779  964704  9647047400002074000008     Rd  Lakeshore Rd  12.517   \n",
       "1      279137  964704  9647047400002874000020     Rd  Lakeshore Rd  12.412   \n",
       "\n",
       "      EMP  all_roads_    spatialjoi  spatialj_1  ...  all_roads1  perrank_nf  \\\n",
       "0  12.598         147  Lakeshore Rd  Huron Walk  ...           3         3.0   \n",
       "1  12.517         147  Lakeshore Rd  Huron Walk  ...           3         3.0   \n",
       "\n",
       "   perrank_cr  perrank_vu perrank_ri  tampnum_ne  ramp  completed_  \\\n",
       "0    2.666667       1.465   1.765417           0     n         NaN   \n",
       "1    2.666667       1.465   1.765417           0     n         NaN   \n",
       "\n",
       "   risk_level  shape_Leng  \n",
       "0         Low  426.267071  \n",
       "1         Low  555.969541  \n",
       "\n",
       "[2 rows x 42 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b57ec156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e8526ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shp = gpd.read_file('detroit_road.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f41061e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-f9363c0cadc6>:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matching_csv_rows['bmp_difference'] = (matching_csv_rows['BMP'] - row_shp['BMP']).abs()\n",
      "<ipython-input-18-f9363c0cadc6>:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matching_csv_rows['bmp_difference'] = (matching_csv_rows['BMP'] - row_shp['BMP']).abs()\n",
      "<ipython-input-18-f9363c0cadc6>:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matching_csv_rows['bmp_difference'] = (matching_csv_rows['BMP'] - row_shp['BMP']).abs()\n",
      "<ipython-input-18-f9363c0cadc6>:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matching_csv_rows['bmp_difference'] = (matching_csv_rows['BMP'] - row_shp['BMP']).abs()\n",
      "<ipython-input-18-f9363c0cadc6>:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matching_csv_rows['bmp_difference'] = (matching_csv_rows['BMP'] - row_shp['BMP']).abs()\n",
      "<ipython-input-18-f9363c0cadc6>:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matching_csv_rows['bmp_difference'] = (matching_csv_rows['BMP'] - row_shp['BMP']).abs()\n",
      "<ipython-input-18-f9363c0cadc6>:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matching_csv_rows['bmp_difference'] = (matching_csv_rows['BMP'] - row_shp['BMP']).abs()\n",
      "<ipython-input-18-f9363c0cadc6>:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matching_csv_rows['bmp_difference'] = (matching_csv_rows['BMP'] - row_shp['BMP']).abs()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming `df_csv` is the DataFrame from the CSV file and `df_shp` is the DataFrame from the DBF of the shapefile\n",
    "\n",
    "# Step 1: Directly merge on unique PR values\n",
    "unique_pr_csv = df_csv[~df_csv['PR'].duplicated(keep=False)]\n",
    "unique_pr_shp = df_shp[~df_shp['PR'].duplicated(keep=False)]\n",
    "merged_unique_pr = pd.merge(unique_pr_shp, unique_pr_csv, on=['PR', 'BMP', 'EMP'], how='inner')\n",
    "\n",
    "# Step 2: Handle duplicate PR values\n",
    "dup_pr_csv = df_csv[df_csv['PR'].duplicated(keep=False)]\n",
    "dup_pr_shp = df_shp[df_shp['PR'].duplicated(keep=False)]\n",
    "\n",
    "# Initialize an empty list to store the merged rows for duplicates\n",
    "merged_dup_pr_rows = []\n",
    "\n",
    "# Loop over each row in `dup_pr_shp` (only rows in shapefile should be retained in the final result)\n",
    "for _, row_shp in dup_pr_shp.iterrows():\n",
    "    # Filter rows in `dup_pr_csv` with the same `PR`\n",
    "    matching_csv_rows = dup_pr_csv[dup_pr_csv['PR'] == row_shp['PR']]\n",
    "    \n",
    "    if not matching_csv_rows.empty:\n",
    "        # Step 2.1: Check for exact matches on BMP\n",
    "        bmp_match = matching_csv_rows[matching_csv_rows['BMP'] == row_shp['BMP']]\n",
    "        \n",
    "        if not bmp_match.empty:\n",
    "            # If a BMP match is found, add to the result\n",
    "            merged_dup_pr_rows.append(pd.concat([row_shp, bmp_match.iloc[0]], axis=1))\n",
    "        else:\n",
    "            # Step 2.2: If no BMP match, check for exact match on EMP\n",
    "            emp_match = matching_csv_rows[matching_csv_rows['EMP'] == row_shp['EMP']]\n",
    "            \n",
    "            if not emp_match.empty:\n",
    "                # If an EMP match is found, add to the result\n",
    "                merged_dup_pr_rows.append(pd.concat([row_shp, emp_match.iloc[0]], axis=1))\n",
    "            else:\n",
    "                # Step 2.3: If no match on BMP or EMP, find the closest BMP\n",
    "                matching_csv_rows['bmp_difference'] = (matching_csv_rows['BMP'] - row_shp['BMP']).abs()\n",
    "                closest_bmp_match = matching_csv_rows.loc[matching_csv_rows['bmp_difference'].idxmin()]\n",
    "                merged_dup_pr_rows.append(pd.concat([row_shp, closest_bmp_match], axis=1))\n",
    "\n",
    "# Concatenate all merged rows for duplicate PR values\n",
    "if merged_dup_pr_rows:\n",
    "    merged_dup_pr = pd.concat(merged_dup_pr_rows, axis=1).T\n",
    "else:\n",
    "    merged_dup_pr = pd.DataFrame()\n",
    "\n",
    "# Step 3: Combine the unique and duplicate PR merges, ensuring only rows from the shapefile remain\n",
    "final_merged_df = pd.concat([merged_unique_pr, merged_dup_pr], ignore_index=True)\n",
    "\n",
    "# Drop any rows that were not originally in the shapefile data (keeping only PRs from `df_shp`)\n",
    "final_merged_df = final_merged_df[final_merged_df['PR'].isin(df_shp['PR'].unique())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "004cc448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DIR</th>\n",
       "      <th>LENGTH</th>\n",
       "      <th>AB_LANES</th>\n",
       "      <th>BA_LANES</th>\n",
       "      <th>CENT_LANE</th>\n",
       "      <th>MODE_ID</th>\n",
       "      <th>NFC</th>\n",
       "      <th>NFC_FLAG</th>\n",
       "      <th>AREA_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>perrank_vu</th>\n",
       "      <th>perrank_ri</th>\n",
       "      <th>tampnum_ne</th>\n",
       "      <th>ramp</th>\n",
       "      <th>completed_</th>\n",
       "      <th>risk_level</th>\n",
       "      <th>shape_Leng</th>\n",
       "      <th>FENAME</th>\n",
       "      <th>FETYPE</th>\n",
       "      <th>bmp_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39957</td>\n",
       "      <td>1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.561667</td>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>819.07689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39932</td>\n",
       "      <td>1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.365</td>\n",
       "      <td>2.690417</td>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>860.148025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39933</td>\n",
       "      <td>1</td>\n",
       "      <td>0.69</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2.2425</td>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3650.074905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22545</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.1075</td>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>767.751115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15899</td>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>RON</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.275</td>\n",
       "      <td>2.372917</td>\n",
       "      <td>0</td>\n",
       "      <td>y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1118.312122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11274</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1975</td>\n",
       "      <td>3.148125</td>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>326.163313</td>\n",
       "      <td>Livernois Ave</td>\n",
       "      <td>Ave</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11275</th>\n",
       "      <td>39855</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bagley</td>\n",
       "      <td>St</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11276</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.29</td>\n",
       "      <td>2.300833</td>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>42.549792</td>\n",
       "      <td>Bagley St</td>\n",
       "      <td>St</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277</th>\n",
       "      <td>39857</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>DV2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3rd</td>\n",
       "      <td>St</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11278</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.005</td>\n",
       "      <td>2.25375</td>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>304.815752</td>\n",
       "      <td>3rd St</td>\n",
       "      <td>St</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11279 rows × 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  DIR LENGTH AB_LANES BA_LANES CENT_LANE MODE_ID  NFC NFC_FLAG  \\\n",
       "0      39957    1   0.16        3        0         0       2    5     None   \n",
       "1      39932    1   0.16        2        0         0       1    3     None   \n",
       "2      39933    1   0.69        2        0         0       1    3     None   \n",
       "3      22545   -1   0.15        0        2         0       2    4     None   \n",
       "4      15899    1   0.21        1        0         0       1    1      RON   \n",
       "...      ...  ...    ...      ...      ...       ...     ...  ...      ...   \n",
       "11274    NaN  NaN    NaN      NaN      NaN       NaN     NaN  NaN      NaN   \n",
       "11275  39855    0   0.01        2        2         0       2    4     None   \n",
       "11276    NaN  NaN    NaN      NaN      NaN       NaN     NaN  NaN      NaN   \n",
       "11277  39857   -1   0.06        0        2         0       2    4      DV2   \n",
       "11278    NaN  NaN    NaN      NaN      NaN       NaN     NaN  NaN      NaN   \n",
       "\n",
       "      AREA_TYPE  ... perrank_vu perrank_ri tampnum_ne ramp completed_  \\\n",
       "0             3  ...       2.86   2.561667          0    n        NaN   \n",
       "1             3  ...      2.365   2.690417          0    n        NaN   \n",
       "2             3  ...       1.99     2.2425          0    n        NaN   \n",
       "3             3  ...       1.81     2.1075          0    n        NaN   \n",
       "4             3  ...      2.275   2.372917          0    y        NaN   \n",
       "...         ...  ...        ...        ...        ...  ...        ...   \n",
       "11274       NaN  ...     3.1975   3.148125          0    n        NaN   \n",
       "11275         1  ...        NaN        NaN        NaN  NaN        NaN   \n",
       "11276       NaN  ...       2.29   2.300833          0    n        NaN   \n",
       "11277         1  ...        NaN        NaN        NaN  NaN        NaN   \n",
       "11278       NaN  ...      2.005    2.25375          0    n        NaN   \n",
       "\n",
       "      risk_level   shape_Leng         FENAME FETYPE bmp_difference  \n",
       "0         Medium    819.07689            NaN    NaN            NaN  \n",
       "1         Medium   860.148025            NaN    NaN            NaN  \n",
       "2         Medium  3650.074905            NaN    NaN            NaN  \n",
       "3         Medium   767.751115            NaN    NaN            NaN  \n",
       "4         Medium  1118.312122            NaN    NaN            NaN  \n",
       "...          ...          ...            ...    ...            ...  \n",
       "11274       High   326.163313  Livernois Ave    Ave            NaN  \n",
       "11275        NaN          NaN         Bagley     St            NaN  \n",
       "11276     Medium    42.549792      Bagley St     St            NaN  \n",
       "11277        NaN          NaN            3rd     St            NaN  \n",
       "11278     Medium   304.815752         3rd St     St            NaN  \n",
       "\n",
       "[11279 rows x 194 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d007e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df.to_csv('Balsal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86315751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce2d03e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-2a92aac5cc25>:19: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gdf.to_file(\"final_merged.shp\")\n"
     ]
    }
   ],
   "source": [
    "# Convert incompatible types to standard Python types\n",
    "for column in final_merged_df.columns:\n",
    "    if final_merged_df[column].dtype == 'int64':\n",
    "        final_merged_df[column] = final_merged_df[column].astype(int)\n",
    "    elif final_merged_df[column].dtype == 'float64':\n",
    "        final_merged_df[column] = final_merged_df[column].astype(float)\n",
    "    elif final_merged_df[column].dtype == 'object':\n",
    "        final_merged_df[column] = final_merged_df[column].astype(str)  # Ensure all object types are strings\n",
    "\n",
    "# Now create the GeoDataFrame and export\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "# Assuming 'geometry' column is already present with LineString geometries\n",
    "gdf = gpd.GeoDataFrame(final_merged_df, geometry='geometry')\n",
    "gdf.set_crs(\"EPSG:4326\", inplace=True)  # Set the CRS\n",
    "\n",
    "# Export to shapefile\n",
    "gdf.to_file(\"final_merged.shp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
